{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import random\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import util.opt as opt\n",
    "from util.data import *\n",
    "from network.net import PConvUNet\n",
    "from util.image import unnormalize\n",
    "from collections import OrderedDict\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_csv = pd.read_csv(\"../dataset/test.csv\")\n",
    "files = test_csv.to_numpy().reshape(-1,)\n",
    "masks_paths =  [\"../dataset/masks/\" + file + \".png\" for file in files]\n",
    "masks = [np.array(Image.open(mask_path)) for mask_path in masks_paths]\n",
    "\n",
    "# compute fill ratio\n",
    "hole2image = [np.sum(mask == 0) / np.prod(mask.shape) for mask in masks]\n",
    "\n",
    "# plot histogram\n",
    "plt.hist(hole2image)\n",
    "plt.xlabel(\"hole to image ratio\")\n",
    "plt.ylabel(\"number of images\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = [0.01, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "disc_hole2image = pd.cut(x=hole2image, bins=bins)\n",
    "disc_hole2image = [str(x) for x in disc_hole2image]\n",
    "\n",
    "dict_masks = {}\n",
    "for i in range(len(masks)):\n",
    "    dh2i = disc_hole2image[i]\n",
    "    \n",
    "    if dh2i == 'nan':\n",
    "        continue\n",
    "        \n",
    "    dict_masks[dh2i] = dict_masks.get(dh2i, []) + [masks[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranges = ['(0.01, 0.1]', '(0.1, 0.2]', '(0.2, 0.3]', '(0.3, 0.4]', '(0.4, 0.5]', '(0.5, 0.6]']\n",
    "values = [len(dict_masks[rng]) for rng in ranges]\n",
    "\n",
    "plt.bar(ranges, values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_func(gts: list, outputs: list, func_name:str):\n",
    "    scores = []\n",
    "    sess = tf.Session()\n",
    "    \n",
    "    with sess.as_default():\n",
    "        for i in range(len(gts)):\n",
    "            gt, output = gts[i], outputs[i]\n",
    "            num_pixels = float(np.prod(gt.shape))\n",
    "            \n",
    "            gt = tf.convert_to_tensor(gt)\n",
    "            output = tf.convert_to_tensor(output)\n",
    "\n",
    "            if func_name == 'PSNR':\n",
    "                score = tf.image.psnr(gt, output, max_val=1.0)\n",
    "            elif func_name == 'SSIM':\n",
    "                score = tf.image.ssim(gt, output, max_val=1.0)\n",
    "            else:\n",
    "                score = tf.divide(tf.reduce_sum(tf.abs(gt - output)), num_pixels / 255.)\n",
    "\n",
    "            score = score.eval()\n",
    "            if score == np.inf:\n",
    "                continue\n",
    "            scores.append(score)\n",
    "            \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary of metric functions\n",
    "metric_funcs = [ \"L1\", \"PSNR\", \"SSIM\"]\n",
    "\n",
    "# dictionary of metric scores\n",
    "metric_scores = {\n",
    "   '(0.01, 0.1]': OrderedDict(), \n",
    "    '(0.1, 0.2]': OrderedDict(), \n",
    "    '(0.2, 0.3]': OrderedDict(), \n",
    "    '(0.3, 0.4]': OrderedDict(), \n",
    "    '(0.4, 0.5]': OrderedDict(), \n",
    "    '(0.5, 0.6]': OrderedDict()\n",
    "}\n",
    "\n",
    "# define device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# create dataset\n",
    "dataset = NusceneDataset('../dataset', train=False)\n",
    "dataloader = DataLoader(dataset, batch_size=32, num_workers=1, drop_last=False)\n",
    "\n",
    "# load model\n",
    "model = PConvUNet().to(device)\n",
    "ckpt_dict = torch.load(\"../snapshots_GAN/ckpt_GAN_alpha_0.75/1000000.pth\")\n",
    "model.load_state_dict(ckpt_dict[\"model\"], strict=False)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for rng in tqdm(dict_masks):\n",
    "    for i, sample in enumerate(dataloader):#len(dataset)):\n",
    "        gts = sample[\"gt\"].float().to(device)\n",
    "        \n",
    "        # sample a random maks from the current range\n",
    "        idx = np.random.choice(np.arange(len(dict_masks[rng])), size=gts.shape[0], replace=True)\n",
    "        masks = [dict_masks[rng][i] for i in idx]\n",
    "        masks = [np.expand_dims(mask / 255., 0).repeat(3, axis=0) for mask in masks]\n",
    "        masks = torch.tensor(np.stack(masks)).float().to(device)\n",
    "        \n",
    "        # image masked\n",
    "        imgs = gts * masks\n",
    "        \n",
    "        # get output\n",
    "        with torch.no_grad():\n",
    "            outputs, _ = model(imgs, masks)\n",
    "        outputs_comp = masks * imgs + (1 - masks) * outputs\n",
    "        \n",
    "        # send back to cpu\n",
    "        gts = gts.cpu()\n",
    "        outputs_comp = outputs_comp.cpu()\n",
    "        \n",
    "        # unnormalize\n",
    "        un_gts = unnormalize(gts)\n",
    "        un_outputs_comp = unnormalize(outputs_comp)\n",
    "        \n",
    "        # get them to range 0, 1\n",
    "        un_gts = torch.clamp(un_gts, 0., 1.)\n",
    "        un_outputs_comp = torch.clamp(un_outputs_comp, 0., 1.)\n",
    "        \n",
    "        # reshape and typing\n",
    "        un_gts = [x.transpose(1, 2, 0) for x in list(un_gts.numpy())]\n",
    "        un_outputs_comp = [x.transpose(1, 2, 0) for x in list(un_outputs_comp.numpy())]\n",
    "        for score_name in metric_funcs:\n",
    "            metric_scores[rng][score_name] = metric_scores[rng].get(score_name, []) + \\\n",
    "                score_func(un_gts, un_outputs_comp, score_name)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics = {}\n",
    "\n",
    "for rng in tqdm(ranges):\n",
    "    statistics[rng] = []\n",
    "\n",
    "    for score_name in metric_funcs:\n",
    "        statistics[rng].append(np.mean(metric_scores[rng][score_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(statistics, index=metric_funcs)\n",
    "results.to_csv(\"../results/vanilla_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(0.01, 0.1]</th>\n",
       "      <th>(0.1, 0.2]</th>\n",
       "      <th>(0.2, 0.3]</th>\n",
       "      <th>(0.3, 0.4]</th>\n",
       "      <th>(0.4, 0.5]</th>\n",
       "      <th>(0.5, 0.6]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1</th>\n",
       "      <td>2.272266</td>\n",
       "      <td>8.035231</td>\n",
       "      <td>12.948554</td>\n",
       "      <td>17.407557</td>\n",
       "      <td>21.516500</td>\n",
       "      <td>32.081116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PSNR</th>\n",
       "      <td>27.541391</td>\n",
       "      <td>20.396593</td>\n",
       "      <td>17.993950</td>\n",
       "      <td>16.615774</td>\n",
       "      <td>15.657435</td>\n",
       "      <td>13.263650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSIM</th>\n",
       "      <td>0.965461</td>\n",
       "      <td>0.884244</td>\n",
       "      <td>0.812185</td>\n",
       "      <td>0.732255</td>\n",
       "      <td>0.663343</td>\n",
       "      <td>0.570515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      (0.01, 0.1]  (0.1, 0.2]  (0.2, 0.3]  (0.3, 0.4]  (0.4, 0.5]  (0.5, 0.6]\n",
       "L1       2.272266    8.035231   12.948554   17.407557   21.516500   32.081116\n",
       "PSNR    27.541391   20.396593   17.993950   16.615774   15.657435   13.263650\n",
       "SSIM     0.965461    0.884244    0.812185    0.732255    0.663343    0.570515"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv(\"../results/GAN_beta_100.00_results.csv\", index_col=0)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv(\"../results/GAN_alpha_0.00_results.csv\", index_col=0)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
