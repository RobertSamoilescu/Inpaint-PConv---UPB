{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, inspect\n",
    "currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "parentdir = os.path.dirname(currentdir)\n",
    "sys.path.insert(0,parentdir)\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL.Image as pil\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "from pipeline.utils import *\n",
    "import imgaug.augmenters as iaa\n",
    "from multiprocessing import Pool, cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_intrinsic():\n",
    "    camera_intrinsic = np.array([\n",
    "        [0.61, 0, 0.5],   # width\n",
    "        [0, 1.22, 0.5],   # height\n",
    "        [0, 0, 1]], dtype=np.float32)\n",
    "        \n",
    "    camera_intrinsic[0, :] *= 256\n",
    "    camera_intrinsic[1, :] *= 128\n",
    "    return camera_intrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_extrinsic():\n",
    "    camera_extrinsic = np.zeros((3, 4), dtype=np.float32)\n",
    "    camera_extrinsic[:3, :3] = np.eye(3)\n",
    "    return camera_extrinsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "monodepth = Monodepth(\"monodepth\", root_dir=\"../pipeline\")\n",
    "\n",
    "def get_depth_map(img: np.array):\n",
    "    global monodepth\n",
    "    \n",
    "    # transform image to tensor\n",
    "    img = img.transpose(2, 0, 1)\n",
    "    timg = torch.tensor(img).unsqueeze(0).float()\n",
    "\n",
    "    # predict depth\n",
    "    tdisp = monodepth.forward(timg)\n",
    "    tdepth = monodepth.get_depth(tdisp)\n",
    "    depth = tdepth.view(img.shape[1], img.shape[2]).numpy()\n",
    "    \n",
    "    return depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_transformation(imgs, intrinsics, extrinsics, depths):\n",
    "    \"\"\"\n",
    "    Generate random transformation\n",
    "    @param imgs:         [B, 3, H, W]\n",
    "    @param depths:       [B, H, W]\n",
    "    @param intrinsics:   [B, 3, 3]\n",
    "    @param extriniscs:   [B, 3, 4]\n",
    "    \"\"\"\n",
    "    # sample random transformation\n",
    "    B = imgs.shape[0]\n",
    "    poses = torch.zeros(B, 6).double()\n",
    "    \n",
    "    tx = torch.zeros(B)\n",
    "    ry = torch.zeros(B)\n",
    "    \n",
    "    if np.random.rand() < 0.33:\n",
    "        tx = .75 * 2 * (torch.rand(B) - 0.5)\n",
    "        ry = .10 * 2 * (torch.rand(B) - 0.5)\n",
    "    else:\n",
    "        if np.random.rand() < 0.5:\n",
    "            tx = 1.5 * 2 * (torch.rand(B) - 0.5)\n",
    "        else:\n",
    "            ry = .20 * 2 * (torch.rand(B) - 0.5) \n",
    "        \n",
    "    poses[:, 0], poses[:, 4] = tx, ry\n",
    "    \n",
    "    # apply transformation - faster inverse-warp\n",
    "    projected_imgs, valid_points = inverse_warp(\n",
    "        img=imgs, \n",
    "        depth=depths, \n",
    "        pose=poses, \n",
    "        intrinsics=intrinsics,\n",
    "        extrinsics=None\n",
    "    )\n",
    "    \n",
    "    # mask of valid points\n",
    "    valid_points = valid_points.double()\n",
    "    projected_imgs = projected_imgs * valid_points.unsqueeze(1)\n",
    "    return projected_imgs, valid_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_video(file: str, src_folder: str, dst_folder: str, verbose: bool = False):\n",
    "    seq = iaa.Sequential([\n",
    "        iaa.CoarseDropout((0.0, 0.10), size_percent=(0.02, 0.25))\n",
    "    ])\n",
    "    \n",
    "    # Create a VideoCapture object and read from input file\n",
    "    # If the input is the camera, pass 0 instead of the video file name\n",
    "    src_path = os.path.join(src_folder, file)\n",
    "    dst_path = dst_folder\n",
    "    cap = cv2.VideoCapture(src_path)\n",
    "    \n",
    "    # Check if camera opened successfully\n",
    "    if (cap.isOpened()== False): \n",
    "        print(\"Error opening video stream or file\")\n",
    "\n",
    "    # make destination folder\n",
    "    if not os.path.exists(dst_path):\n",
    "        os.makedirs(dst_path)\n",
    "        \n",
    "    # frame index    \n",
    "    frame_idx = 0    \n",
    "    \n",
    "    # Read until video is completed\n",
    "    while(cap.isOpened()):\n",
    "        # Capture frame-by-frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if ret == True:\n",
    "            frame = frame[:320, ...]\n",
    "            \n",
    "            # Display the resulting frame\n",
    "            if verbose:\n",
    "                cv2.imshow('Frame',frame)\n",
    "            \n",
    "            # save frame image\n",
    "            img_path = os.path.join(dst_path, \"imgs\", file[:-6] + \".\" + str(frame_idx) + \".png\")\n",
    "            img = pil.fromarray(frame[..., ::-1])\n",
    "            resized_img = img.resize((256, 128))\n",
    "            resized_img.save(img_path, 'png')\n",
    "            \n",
    "            # predict depth and save it\n",
    "            resized_img = img.resize((512, 256))\n",
    "            resized_img = np.asarray(resized_img)\n",
    "            depth = get_depth_map(resized_img)\n",
    "            resized_depth = cv2.resize(depth, dsize=(256, 128))\n",
    "            depth_path = os.path.join(dst_path, \"depths\", file[:-6] + \".\" + str(frame_idx) + \".pkl\")\n",
    "            with open(depth_path, \"wb\") as fout:\n",
    "                pkl.dump(resized_depth, fout)\n",
    "                \n",
    "            #save camera intrinsic\n",
    "            camera_intrinsic = get_camera_intrinsic()\n",
    "            camera_intrinsic_path = os.path.join(dst_path, \"intrinsics\", file[:-6] + \".\" + str(frame_idx) + \".pkl\")\n",
    "            with open(camera_intrinsic_path, \"wb\") as fout:\n",
    "                pkl.dump(camera_intrinsic, fout)\n",
    "                \n",
    "            # save camera extrinsic\n",
    "            camera_extrinsic = get_camera_extrinsic()\n",
    "            camera_extrinsic_path = os.path.join(dst_path, \"extrinsics\", file[:-6] + \".\" + str(frame_idx) + \".pkl\")\n",
    "            with open(camera_extrinsic_path, \"wb\") as fout:\n",
    "                pkl.dump(camera_extrinsic, fout)\n",
    "                \n",
    "            # generate mask\n",
    "            timg = torch.tensor(resized_img.transpose(2, 0, 1)).unsqueeze(0).double()\n",
    "            tdepth = torch.tensor(resized_depth).unsqueeze(0).double()\n",
    "            tintrinsic = torch.tensor(camera_intrinsic).unsqueeze(0).double()\n",
    "            textrinsic = torch.tensor(camera_extrinsic).unsqueeze(0).double()\n",
    "            \n",
    "            # projection\n",
    "            tprojected_img, tvalid_points = random_transformation(timg, tintrinsic, textrinsic, tdepth)\n",
    "            \n",
    "            # mask\n",
    "            mask = 255 * tvalid_points.to(torch.uint8).squeeze(0).numpy()\n",
    "            mask = seq(images=mask)\n",
    "            mask_path = os.path.join(dst_path, \"masks\", file[:-6] + \".\" + str(frame_idx) + \".png\")\n",
    "            cv2.imwrite(mask_path, mask)\n",
    "                \n",
    "            # increment number of frame\n",
    "            frame_idx += 1 \n",
    "                \n",
    "            # Press Q on keyboard to  exit\n",
    "            if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                break\n",
    "                \n",
    "        # Break the loop\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # When everything done, release the video capture object\n",
    "    cap.release()\n",
    "\n",
    "    # Closes all the frames\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [11:09<00:00,  8.27s/it]\n"
     ]
    }
   ],
   "source": [
    "SRC_FOLDER = '/home/robert/PycharmProjects/EvalSteeringModel/test_data'\n",
    "DST_FOLDER = '../dataset'\n",
    "videos = os.listdir(SRC_FOLDER)\n",
    "videos = [v for v in videos if v.endswith('.mov')]\n",
    "\n",
    "for v in tqdm(videos):\n",
    "    read_video(v, SRC_FOLDER, DST_FOLDER, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
